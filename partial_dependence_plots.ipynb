{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Partial Dependence Plot (PDP) visualises the impact of one or two features on model outcome.\n",
    "\n",
    "# How it works\n",
    "1. Once a model is trained on a dataset, a feature of interest is selected. Let's assume for clarity that the features in the dataset are X1, X2, X3, and X4; and X1 is the feature of interest.\n",
    "2. Set X1 to the same value in all of the rows in the datasets, and then calculate the predicted outcome of the model for each row and average the predicted outcomes.\n",
    "3. Repeat Step 2 for another value of X1.\n",
    "4. A plot of X1 against the average predicted outcomes is drawn, which shows the impact of the change in values of X1 on the model prediction. \n",
    "5. Repeat Step 2, 3, 4 for another feature, as needed.\n",
    "\n",
    "Note: One feature of interest produces 2D plots. Two simultaneous features of interest produce 3D plots. Therefore, it will be challenging to plot the partial dependences if the features of interest are more than two.\n",
    "\n",
    "# When to use\n",
    "[]\n",
    "\n",
    "# Pros\n",
    "- Model agnostic, and it is applicable for both regression and classification tasks.\n",
    "- Visual. Easy to understand.\n",
    "- Global method. PDP explains the global relationship of a feature with the predicted outcome.\n",
    "\n",
    "# Cons\n",
    "- PDP assumes the features are independent, which may not be true for 'real' datasets.\n",
    "- Fixing the feature of interest to a particular value may introduce an impossible scenario i.e. observation that can not exist.\n",
    "- Averaging the predicted outcomes of each row provide limited information. A standard deviation of the predicted outcomes, for example, will be helpful to better understand the impact of a given feature."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
