{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Tools like SHAP, LIME, and Partial Dependence Plot show which feature contribute more to the predicted outcome. Counterfactual works in the opposite direction i.e. which feature do we update in order to minimize the value of the preidicted outcome. \n",
    "\n",
    "\n",
    "Counterfactuals are also called contrastive explanations.\n",
    "\n",
    "\n",
    "### Motivation\n",
    "In image classification, adding minimal noise to an image can change the prediction of an image from, let's say, a 'panda' to a 'gibbon'. Say, we are interested in identifying minimum change to the input image that changes the prediction from a panda to a gibbon. We can find that out by solving the following optimization problem:\n",
    "\n",
    "$$\n",
    "argmin_{x'} \\quad d(x, x') \\quad s.t. \\quad f(x') = c\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x$ is an observation from the dataset\n",
    "- $f(.)$ is the model\n",
    "- $x'$ is the perturbed observation\n",
    "- $d()$ is a distance function\n",
    "\n",
    "# How it works\n",
    "Counterfactuals can be implemented as both model-specific and model-agnostic; and there are several implemenations of both.\n",
    "\n",
    "\n",
    "# Pros\n",
    "\n",
    "\n",
    "\n",
    "# Cons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".xai38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
